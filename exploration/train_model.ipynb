{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook containing examples on how to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/mqd4g8995xqfhcvcyvr2smdc0000gn/T/ipykernel_96871/933801931.py:26: DtypeWarning: Columns (7,11,23,45,46,47,55,65,69,75,86,102) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../data/derived/DENGSP.csv')\n",
      "2024-12-15 01:04:17.910 | WARNING  | forecastpnn.utils.data_functions:get_dataset:228 - If output data is indexed by weeks, day of the weeks cannot be used as feature, so keyword dow will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloaded\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(os.getcwd()).parent / 'src'))\n",
    "from forecastpnn.utils.data_functions import get_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler as SRS\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "torch.use_deterministic_algorithms(True) # reproducibility\n",
    "import pandas as pd\n",
    "\n",
    "from forecastpnn.utils.train_utils import SubsetSampler as SS\n",
    "from forecastpnn.utils.constants import RANDOM_SEED\n",
    "\n",
    "WEEKS = True\n",
    "PAST_UNITS = 12\n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SPLIT = False\n",
    "DEVICE = \"mps\"\n",
    "\n",
    "data = pd.read_csv('../data/derived/DENGSP.csv')\n",
    "dl = get_dataset(data, 'DT_SIN_PRI', weeks_in=False, weeks_out=WEEKS, past_units=PAST_UNITS, return_df=False, filter_year_min=2013, filter_year_max=2020)\n",
    "\n",
    "#n_obs_40pu = len(dataset) # 2922 total dates, -39-39 for past_units and max_delay ->2844\n",
    "## Define train and test indices\n",
    "if RANDOM_SPLIT:\n",
    "    all_idcs = range(dl.__len__())\n",
    "    train_idcs, test_idcs = TTS(all_idcs, test_size=0.25, shuffle=True, random_state=RANDOM_SEED)\n",
    "    train_idcs, val_idcs = TTS(train_idcs, test_size=0.25, shuffle=True, random_state=RANDOM_SEED)\n",
    "    #train_idcs, test_idcs = [*range(600), *range(950, dataset.__len__())], [*range(600, 950)]\n",
    "    VAL_BATCH_SIZE, TEST_BATCH_SIZE = len(val_idcs), len(test_idcs)\n",
    "else:\n",
    "    if WEEKS: # could also do random split, for now last indices as test\n",
    "        train_idcs, test_idcs = range(300), range(300, dl.__len__())\n",
    "        train_idcs, val_idcs = TTS(train_idcs, test_size=0.25, shuffle=True, random_state=RANDOM_SEED)\n",
    "        VAL_BATCH_SIZE, TEST_BATCH_SIZE = len(val_idcs), len(test_idcs)\n",
    "    else: \n",
    "        train_idcs, test_idcs = range(int(0.75*dl.__len__())), range(int(0.75*dl.__len__()), dl.__len__()) # 2844 total obs - 711 test, still 25% even without random split, last outbreak 2353\n",
    "        train_idcs, val_idcs = TTS(train_idcs, test_size=0.25, shuffle=True, random_state=RANDOM_SEED)\n",
    "        VAL_BATCH_SIZE, TEST_BATCH_SIZE = len(val_idcs), len(test_idcs)\n",
    "        \n",
    "## Define generator so sampling during training is deterministic and reproducible\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RANDOM_SEED)\n",
    "train_sampler, val_sampler, test_sampler = SRS(train_idcs, generator=g), SRS(val_idcs), SS(test_idcs)\n",
    "train_loader, val_loader, test_loader = DataLoader(dl, batch_size=BATCH_SIZE, sampler=train_sampler), DataLoader(dl, batch_size=VAL_BATCH_SIZE, sampler=val_sampler, shuffle=False), DataLoader(dl, batch_size=TEST_BATCH_SIZE, sampler=test_sampler, shuffle=False)\n",
    "\n",
    "## Function to reset the sampler so each training run uses same order of observations for reproducibility\n",
    "## Possible to define s.t. returns train_loader, but bc in notebook, possible to define globally\n",
    "def regen_data():\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(RANDOM_SEED)\n",
    "    global train_loader\n",
    "    train_loader = DataLoader(dl, batch_size=BATCH_SIZE, sampler=SRS(train_idcs, generator=g))\n",
    "\n",
    "def set_seeds(SEED):\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "set_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1867.,  1664.,  1238., 62633.,  2480.,  2009.,  2010.,  1004.,  5453.,\n",
      "         2126.,  3667.,  1406.,  1445., 73235.,  1037.,  9927.,  2588., 32946.,\n",
      "          931.,   964.,  1123.,   611.,   782.,   710.,  1743.,  2166.,  2095.,\n",
      "         1856., 30177.,  1564., 51051.,  2151.,   826., 30018., 82639.,  1831.,\n",
      "        23043., 20739.,  1873.,   748.,  2198.,  1861.,  1125.,  1744.,  1381.,\n",
      "         1168.,  1346.,  2675.,   826.,  2788.,  2182.,  1666.,  2105.,  4436.,\n",
      "         1880., 63046.,  1155.,  1764.,  2250.,   805.,   970.,  1232.,  5378.,\n",
      "        18224.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 68636.2031,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,   421.4409,     0.0000,\n",
      "            0.0000, 82597.5312,     0.0000,  3214.1704,     0.0000, 27834.4023,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 30010.4883,     0.0000,\n",
      "        53864.8516,     0.0000,     0.0000, 24877.2637, 76416.8594,     0.0000,\n",
      "        14015.0420, 26163.3203,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,   618.8496,\n",
      "            0.0000, 68097.3359,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  2620.0376, 11513.2441], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2381., 42059.,  2022.,   830., 13332.,  1730.,  1627.,  2046.,  2236.,\n",
      "         3193.,  6244.,  2028.,  2136.,  6700.,  1315.,  2409.,  7515., 29194.,\n",
      "         1674.,  6328.,  1604.,  1617.,  1547.,  1317.,  3414.,  1697.,   619.,\n",
      "         1983.,   775.,   961.,   576.,  1529.,  1298.,  1145.,  1358.,  2607.,\n",
      "         2181.,   853.,   733.,   664.,  9618.,  2373.,  1563.,  4449.,  1366.,\n",
      "          692.,  2371.,  2923.,  5342.,   695.,  4843.,  1065.,  1752.,  7858.,\n",
      "        38756.,  1708.,   710., 12421.,  1131.,  2576., 22151.,  2242., 13464.,\n",
      "         2699.], device='mps:0')\n",
      "tensor([    0.0000, 31302.9199,     0.0000,     0.0000,  5844.5371,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2457.4282,     0.0000,\n",
      "            0.0000,  2866.7449,     0.0000,     0.0000,  2228.8140, 23697.7871,\n",
      "            0.0000,  1145.8472,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  8618.1875,     0.0000,\n",
      "            0.0000,   488.6489,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  2781.3169,     0.0000,     0.0000,  7949.3311,\n",
      "        46787.6172,     0.0000,     0.0000, 11881.6914,     0.0000,     0.0000,\n",
      "        17119.1523,     0.0000, 15251.7754,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2326.,  8880.,  1691.,  1048., 31871.,  2013.,  3821.,  3693.,  2743.,\n",
      "          866.,  9577.,   688.,   665.,   569.,  5753.,  1994.,  2492.,  6716.,\n",
      "        25462., 32960., 12018.,  2097.,   895., 33053.,  1342.,  1069.,   632.,\n",
      "         1583.,  1047.,  1255., 30094.,   706.,   692., 18943., 34414.,   889.,\n",
      "          872.,  4406.,  2534.,  1083.,  1156.,  1974., 27062.,  1186.,  2154.,\n",
      "          803., 29401.,  1647.,   913.,  2839., 24535.,  1928.,  2055.,   854.,\n",
      "          710.,  1169.,   746.,  1648.,   978.,  1925., 31082.,  1918.,  2241.,\n",
      "         2150.], device='mps:0')\n",
      "tensor([    0.0000,  8153.8511,     0.0000,     0.0000, 21476.7695,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2464.0471,     0.0000,\n",
      "            0.0000,     0.0000,  2575.1562,     0.0000,     0.0000,  3515.8984,\n",
      "        27316.3926, 28321.0938, 12056.0410,     0.0000,     0.0000, 27758.6895,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        19269.4258,     0.0000,     0.0000, 18376.3418, 26351.3262,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        25909.9785,     0.0000,     0.0000,     0.0000, 31146.5645,     0.0000,\n",
      "            0.0000,     0.0000, 25571.4434,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        27056.2969,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([30073.,  3687.,  2108.,  1400.,  6490.,   569.,  1883., 23783., 22610.,\n",
      "         1749.,  1132.,  1915., 16544.,  1986.,  6495.,  2137.,  1833.,  2024.,\n",
      "         1815.,   985.,  2332.,  2321.,  2203.,  2174.,  2449.,  2066.,  2009.,\n",
      "         1951.,   834.,  8687.,   991., 26691.,  1616.], device='mps:0')\n",
      "tensor([27376.7188,     0.0000,     0.0000,     0.0000,  3440.2786,     0.0000,\n",
      "            0.0000, 12375.7637, 22325.9180,     0.0000,     0.0000,     0.0000,\n",
      "        20010.9824,     0.0000,   726.2422,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,  8430.2412,\n",
      "            0.0000, 19596.1738,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 1 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 1317., 51051.,   866.,  1752., 73235.,   632.,  1065.,  2028.,  6328.,\n",
      "         1125., 12421.,   706.,  1925., 26691.,  3667.,  2151.,  1861.,  2492.,\n",
      "         1815.,   872.,  1358.,  1004.,   688.,   576.,  1083.,  1883.,  3693.,\n",
      "         8687.,  2009., 22151.,  2055.,   746.,   692.,  1232.,  1048.,   748.,\n",
      "         5378.,  2198.,  1983.,  1315.,  2013.,  6495.,  1169.,  2236., 82639.,\n",
      "         4449.,  3193., 23783.,  6716.,  1674.,  1856.,   710.,  1974.,  1951.,\n",
      "         9577.,  1915.,  1563.,  1255., 13332.,  2150.,  3414.,  1168.,   695.,\n",
      "         5342.], device='mps:0')\n",
      "tensor([    0.0000, 56584.9180,     0.0000,     0.0000, 79418.4766,     0.0000,\n",
      "            0.0000,     0.0000,  1574.8352,     0.0000, 11765.8125,     0.0000,\n",
      "            0.0000, 18022.7148,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  7119.6411,     0.0000, 16760.7402,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         1444.5503,     0.0000,     0.0000,     0.0000,     0.0000,   821.3481,\n",
      "            0.0000,     0.0000, 76557.7734,     0.0000,     0.0000, 12413.5850,\n",
      "         4429.0630,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         2394.0872,     0.0000,     0.0000,     0.0000,  6394.5669,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,   527.4590], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 5453.,   826.,  2607., 63046.,  1764.,  1627.,  1346.,  1873.,  1238.,\n",
      "         1529.,  2010.,  1880.,  1145.,  2321.,  9618.,  1928.,  2066.,  1697.,\n",
      "        42059.,  1131.,  2166.,  1730.,  1381.,   853., 23043.,   692.,  2174.,\n",
      "         6490.,  2105., 22610.,   931.,  2241.,   665.,   569., 30094.,   970.,\n",
      "         1400., 13464.,  2136., 20739.,  2409.,  1986., 30018.,  1647.,  1708.,\n",
      "         2923.,   985.,  3821.,   834.,   803., 62633.,  1342.,  2480., 31871.,\n",
      "         1298., 12018.,   978.,  2182.,  2449., 32946.,  2250.,  1617.,  1037.,\n",
      "         1047.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 65704.3125,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  8738.4307,     0.0000,     0.0000,     0.0000,\n",
      "        29551.7461,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        13754.2129,     0.0000,     0.0000,  2885.8455,     0.0000, 22504.5645,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 18790.5371,     0.0000,\n",
      "            0.0000, 13534.0166,     0.0000, 26105.3398,     0.0000,     0.0000,\n",
      "        24872.9023,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 72213.6641,     0.0000,     0.0000, 22926.7500,\n",
      "            0.0000, 13152.7705,     0.0000,     0.0000,     0.0000, 29659.8516,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([24535.,  8880.,  1743.,  7515.,  6244.,  1069.,  1156.,  2588.,  1831.,\n",
      "          710.,  2242.,   710.,  1186.,   991.,  2326., 30177.,  1616.,  1918.,\n",
      "        34414.,  1666.,  2126.,  1583.,  2022., 18943.,  1445.,  1406.,   611.,\n",
      "        38756.,  2095.,   805.,  2024.,  1744.,  2046.,   961.,  9927.,  1833.,\n",
      "          733.,  1155., 16544.,  2534.,  7858., 25462.,   826.,  2381.,  2137.,\n",
      "         1691.,   913.,  2097.,  4406.,  5753.,  2743.,  1648.,  2373.,  2839.,\n",
      "         2371.,  2108.,  2576.,   782.,  1994.,  2009.,  1123.,   889.,  6700.,\n",
      "          854.], device='mps:0')\n",
      "tensor([26456.0957,  7555.4600,     0.0000,  1988.5781,  1878.0293,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 30358.9473,     0.0000,     0.0000,\n",
      "        28864.5000,     0.0000,     0.0000,     0.0000,     0.0000, 17017.5273,\n",
      "            0.0000,     0.0000,     0.0000, 48729.3320,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  3864.0579,     0.0000,\n",
      "            0.0000,     0.0000, 17882.1992,     0.0000,  7340.6538, 26466.3652,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  1688.4722,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  2777.0151,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 3687.,   895., 33053.,  1132.,  2699.,  2675.,  2181.,  2154., 30073.,\n",
      "        29194.,  1604.,  2203.,   619.,  1749.,  1366.,   664., 31082., 29401.,\n",
      "         1547.,  4436., 32960.,  2788.,   569.,   964., 27062.,  1664.,  2332.,\n",
      "        18224.,  4843.,  1564.,   775.,  1867.,   830.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000, 25646.1504,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 28464.6680, 24003.6172,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 26407.3242, 29525.2539,\n",
      "            0.0000,   536.8911, 29297.2051,     0.0000,     0.0000,     0.0000,\n",
      "        26698.4121,     0.0000,     0.0000, 11553.6572,  3208.8340,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 2 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([  985.,  2576.,  2332., 29401.,  2241.,  1951.,   889., 33053.,  1915.,\n",
      "          895.,  1186.,  2588.,  2136.,   830.,   569.,  8880.,  5753.,   961.,\n",
      "         1168.,  1744.,   782.,  2010., 32946.,  1815.,  1342.,  1069.,  2154.,\n",
      "         2236.,  2166., 27062.,   970., 30073.,   866.,  2097., 62633.,   853.,\n",
      "         1925., 23043.,  1131.,  2923.,   805.,  2095.,  1833., 30177.,  9618.,\n",
      "          834.,  1083., 16544.,  2788.,  2150.,  1708.,   576.,  1883.,  1298.,\n",
      "         2009.,  1831.,  1647.,  1616.,  1564.,  2409., 25462.,  6716.,  1123.,\n",
      "         3821.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 29384.5020,     0.0000,     0.0000,\n",
      "            0.0000, 24853.0254,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  6766.4941,  1722.0938,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 28159.6934,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 26156.5156,\n",
      "            0.0000, 26840.8457,     0.0000,     0.0000, 70805.8281,     0.0000,\n",
      "            0.0000, 14126.8398,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 31742.3750,  8561.4648,     0.0000,     0.0000, 18243.1289,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        27234.7441,  4593.8184,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2028.,  2055.,  6328.,  1983., 12018.,   695.,  4843.,   688.,  1861.,\n",
      "         2607.,  1867., 82639., 73235.,  1366.,  1986.,  6495.,   619.,  1664.,\n",
      "        29194.,  2373.,  7858.,  9577.,  6490.,   978.,  1994.,  2126.,   632.,\n",
      "          826.,  1381.,  1125.,  1238.,  2066.,   872.,  2242.,   913.,   611.,\n",
      "          746.,  2181.,  1604.,  2198.,  1563., 34414.,  1730.,  2381.,   931.,\n",
      "        32960.,  2203.,  1743., 30018., 22610.,  3693., 42059.,  2022., 63046.,\n",
      "         1346.,  1674.,   803.,  2013., 22151.,  2675., 12421.,  1156.,  1132.,\n",
      "         2480.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,   608.3843,     0.0000, 14004.6016,     0.0000,\n",
      "         3625.6362,     0.0000,     0.0000,     0.0000,     0.0000, 72791.7188,\n",
      "        79355.0234,     0.0000,     0.0000,   995.5107,     0.0000,     0.0000,\n",
      "        22121.9863,     0.0000,  7066.9917,  1903.0923,  2135.9619,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 28125.1777,\n",
      "            0.0000,     0.0000,     0.0000, 29307.3203,     0.0000,     0.0000,\n",
      "        24512.6406, 21242.3086,     0.0000, 32820.5547,     0.0000, 65081.2422,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 16688.2109,     0.0000,\n",
      "        10904.2305,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([31082., 18943.,  1048.,   569.,   710., 31871.,  7515.,  2743.,  2371.,\n",
      "         1873.,   733.,  3667.,  2046., 13332.,   692.,  1155.,  8687.,  1047.,\n",
      "         1169.,   991.,  2839.,  1255., 26691.,  2024.,   664.,  2492.,  1928.,\n",
      "         1583., 23783.,  9927.,   826.,  1065.,  1317.,  2326.,  6244.,   854.,\n",
      "         5342.,  2321.,  2250.,  1648.,  1691.,  3687., 13464.,  1856.,  1627.,\n",
      "          706.,  1974.,  1697., 18224.,  2182.,   692.,  1445.,  6700.,  1749.,\n",
      "         4406.,  2534.,  2105.,  5378., 30094.,  3193.,  1918.,  4449.,  1617.,\n",
      "         1406.], device='mps:0')\n",
      "tensor([27253.6660, 18191.6758,     0.0000,     0.0000,     0.0000, 21059.9082,\n",
      "         1410.6592,     0.0000,     0.0000,     0.0000,     0.0000,    46.3555,\n",
      "            0.0000,  6506.7773,     0.0000,     0.0000,  6860.4233,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 18116.6211,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 12592.5898,  4106.8198,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  1431.1821,     0.0000,\n",
      "         1670.1248,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        14644.9424,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        11515.0820,     0.0000,     0.0000,     0.0000,  3312.2366,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  2385.2686, 19293.5703,     0.0000,\n",
      "            0.0000,   222.6919,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1037.,  1880.,  1547.,  1145.,  2009.,   710.,  1315.,   775.,  2174.,\n",
      "         2108.,  2449.,  1764., 51051., 38756.,  1400.,  2151.,  1358.,   665.,\n",
      "         1529.,  2137.,  1232.,  4436.,   710.,  5453.,  1752., 24535.,  1004.,\n",
      "         1666., 20739.,   748.,   964.,  3414.,  2699.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        54409.5000, 47488.5117,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,   868.6206,     0.0000,    82.1865,\n",
      "            0.0000, 26321.8926,     0.0000,     0.0000, 27898.4277,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 3 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2154.,  2321.,  7515., 12421.,  1123.,  2203.,   826.,   692., 26691.,\n",
      "         2150.,  4406.,   826.,  1563., 51051.,   706.,  1169., 32946.,  2136.,\n",
      "        23783.,   872., 18224.,  7858.,  1047.,   692.,  2576.,  1951.,   782.,\n",
      "         2013., 20739.,  2607.,  2024.,  6700.,  1880.,  1004.,  2381.,   748.,\n",
      "         2675.,   834.,  5342., 82639.,  3693.,   931.,  5453., 31871.,   733.,\n",
      "         2332.,  2126.,   895.,  2181.,   688.,   710.,  6716.,  1697., 13464.,\n",
      "          664.,  2480.,   632.,   569., 27062.,  3821.,  2137., 73235.,   775.,\n",
      "        13332.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,  2340.2410, 11047.8340,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 17866.5664,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 56199.1016,     0.0000,     0.0000, 27286.3340,     0.0000,\n",
      "        13617.0625,     0.0000, 11568.5508,  7117.3145,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 24619.5059,     0.0000,\n",
      "            0.0000,  2606.5718,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,    82.8237, 72593.3672,     0.0000,     0.0000,\n",
      "         1213.4805, 21337.9336,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  4544.3032,     0.0000, 14408.1797,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 25557.1133,     0.0000,\n",
      "            0.0000, 82057.9297,     0.0000,  6174.0498], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2236.,   853.,  1764.,  1994.,  1547.,  2923.,  1983.,  1856.,  1752.,\n",
      "        23043.,   611.,  1928.,  1255.,  1666.,  1156.,   854.,  2492.,  2009.,\n",
      "         1298.,  1617.,  1918.,   889.,  1168.,  5378.,  2009.,   695.,  8687.,\n",
      "         2788.,  1069.,   576.,  2182.,  1647.,  1381., 30018.,  1132.,  1155.,\n",
      "         4449., 30094.,  1232.,  5753.,  6490.,  1065.,  1358.,  2028.,   961.,\n",
      "         2166.,  1833.,  1815.,   569.,  1406., 29401.,  2371.,   913.,   710.,\n",
      "        24535., 22610.,  6495., 63046.,  1873.,  3667.,  2010.,  2449.,  1749.,\n",
      "         1315.], device='mps:0')\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4677e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7790e+03,\n",
      "        0.0000e+00, 0.0000e+00, 8.0082e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5776e+04, 0.0000e+00, 0.0000e+00,\n",
      "        5.0247e+01, 1.9232e+04, 0.0000e+00, 3.1196e+03, 1.7255e+03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.0480e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.6681e+04, 2.2960e+04, 1.7275e+03, 6.6115e+04, 0.0000e+00, 4.1670e+02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1674.,  1604.,  1037.,  1564.,  1616., 31082.,  9577.,  1583.,  4843.,\n",
      "         2055.,  2242.,  3687.,  2151., 30073.,   805., 34414.,  1730., 30177.,\n",
      "         1691.,  1883.,  2046.,  1708.,  2743., 18943.,  1915., 25462., 32960.,\n",
      "          710.,  3193.,  2839.,  9618.,  1648.,  1400.,  1744.,   978., 38756.,\n",
      "          619.,  2373.,   665.,  1743.,  6244.,  1342.,  2022.,   991.,  9927.,\n",
      "        16544., 29194.,   970.,  1627.,  2105.,  2250.,  1317., 42059.,  1925.,\n",
      "         1974.,   985.,  1664.,  2066.,  1861.,  1131., 33053.,  1346.,   830.,\n",
      "         1125.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 27594.8535,\n",
      "         2977.0854,     0.0000,  3058.5244,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 29045.7188,     0.0000, 26413.8398,     0.0000, 28921.5430,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 17929.1738,\n",
      "            0.0000, 26107.9609, 28992.3340,     0.0000,     0.0000,     0.0000,\n",
      "         9331.4473,     0.0000,     0.0000,     0.0000,     0.0000, 46353.1953,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  3598.9397,     0.0000,\n",
      "            0.0000,     0.0000,  2606.2505, 18421.7168, 21688.3613,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 32887.7852,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        27560.0078,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1445.,  2241.,  2095.,  8880.,   866.,  1048.,  1083.,  1831.,  2409.,\n",
      "         2588.,  2326.,   964.,  2097.,  1145.,  1186.,  2198.,   803.,  1867.,\n",
      "         1238.,   746.,  2699.,  1366.,  2534.,  2108.,  1529.,  2174.,  6328.,\n",
      "        12018.,  3414., 22151., 62633.,  4436.,  1986.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,  7929.0176,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,   715.5771, 12217.0410,     0.0000, 17796.2344,\n",
      "        72644.1953,   421.7754,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 4 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([82639.,  1617.,  2699.,  2150.,   569.,   706.,  1131., 42059.,   889.,\n",
      "         1547.,  1666.,  2055., 73235.,   632.,   664.,   853.,  9577.,  2326.,\n",
      "         1861.,  1918., 27062., 22610.,  5753.,  2013.,  2250.,  8687.,  1342.,\n",
      "          710.,  5342.,  1647.,  1583.,  1156.,  2105.,  1986.,  4843.,   688.,\n",
      "         1674., 29194.,  2381.,  1298., 13464.,   805.,   619.,  2095.,  1406.,\n",
      "        26691.,   692.,  6244.,  1346.,  1883.,  1764.,   854.,  1358.,   692.,\n",
      "         1168.,  2788.,  2028.,  4406.,   826., 38756.,   872.,  2923.,  1749.,\n",
      "         7515.], device='mps:0')\n",
      "tensor([77278.0547,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 30461.1777,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        78907.9766,     0.0000,     0.0000,     0.0000,  3378.1086,     0.0000,\n",
      "            0.0000,     0.0000, 25071.5039, 22671.0684,  1848.4263,     0.0000,\n",
      "            0.0000,  8223.8828,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  3531.7065,     0.0000,\n",
      "            0.0000, 22410.6973,     0.0000,     0.0000, 13599.1562,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 17751.5391,     0.0000,  1597.0820,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 47441.1367,\n",
      "            0.0000,     0.0000,     0.0000,  2325.2339], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2046.,  6490.,  1564., 31082.,   834., 34414.,   782.,  1856.,  1169.,\n",
      "        32960.,   830.,  3193.,  3687.,  2607.,  1563.,  1708., 24535.,  1994.,\n",
      "         1132., 18224.,  6495.,   695.,  1983.,  4436.,   826.,  2108.,  3821.,\n",
      "        23783., 31871.,  7858., 30073.,  5378.,   913.,  1155.,  1867.,  6700.,\n",
      "        30018.,  2198.,  1186.,  1004.,  9927.,   895.,   803.,  1880.,  1069.,\n",
      "         1664.,  2839.,   748.,  2409.,  1048.,  1730.,  2332.,  2534.,   985.,\n",
      "        23043.,  2675.,   964.,  1951.,  1037.,  2066.,  3414.,  2126.,  2203.,\n",
      "          866.], device='mps:0')\n",
      "tensor([    0.0000,  2645.6492,     0.0000, 26249.0391,     0.0000, 29509.9980,\n",
      "            0.0000,     0.0000,     0.0000, 31114.3555,     0.0000,     0.0000,\n",
      "          356.2900,     0.0000,     0.0000,     0.0000, 24732.2051,     0.0000,\n",
      "            0.0000, 11574.9912,   534.5571,     0.0000,     0.0000,   750.6714,\n",
      "            0.0000,     0.0000,     0.0000, 13941.9336, 22957.2773,  6225.9741,\n",
      "        27403.3535,  1837.2051,     0.0000,     0.0000,     0.0000,  1595.9502,\n",
      "        25349.3086,     0.0000,     0.0000,     0.0000,  3854.7568,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        13639.7051,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1529.,  2241.,  6716.,  2024.,  1616., 30177.,  1928.,  1743.,  1083.,\n",
      "         2022.,   665.,  1232.,  1873.,  2097.,  2236.,  1317.,  2588.,  2373.,\n",
      "         9618.,   961.,  1974.,  2242.,  2136., 20739.,  1381., 63046.,  2182.,\n",
      "         1125.,  1400.,  2151., 32946.,   710., 62633.,  1047.,   710.,  1691.,\n",
      "          611.,  1123.,   931.,  1697.,  8880.,  2576., 18943.,  1145.,  2181.,\n",
      "        25462.,  2743.,  2166.,  1627., 13332.,  1831.,   978.,  3693., 51051.,\n",
      "          970.,  2174.,  2154., 12421.,  1604.,  2009.,  2371.,  1815.,  2137.,\n",
      "         2449.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,  4318.1572,     0.0000,     0.0000, 29645.4473,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         8138.9224,     0.0000,     0.0000,     0.0000,     0.0000, 25835.7754,\n",
      "            0.0000, 68433.5625,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        28628.5312,     0.0000, 71067.0469,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  8602.9482,     0.0000,\n",
      "        19139.8555,     0.0000,     0.0000, 26638.6406,     0.0000,     0.0000,\n",
      "            0.0000,  5010.4531,     0.0000,     0.0000,    87.9902, 54057.4961,\n",
      "            0.0000,     0.0000,     0.0000, 10718.5762,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1752.,  1744.,  3667.,  1445.,  1315.,  1065., 33053., 12018.,  2321.,\n",
      "          746., 16544.,  1648.,  1255.,  6328.,   775.,   576.,  2492., 30094.,\n",
      "          991.,  1915.,  1366.,  1238.,  4449., 22151.,  1833.,  1925., 29401.,\n",
      "         2480.,  5453.,   733.,  2009.,   569.,  2010.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,   971.4355,     0.0000,     0.0000,     0.0000,\n",
      "        24752.3984, 13561.5156,     0.0000,     0.0000, 20170.3398,     0.0000,\n",
      "            0.0000,   494.4438,     0.0000,     0.0000,     0.0000, 20734.6113,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,   407.0059, 17107.2422,\n",
      "            0.0000,     0.0000, 29800.2324,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 5 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2108.,  1951.,  1983., 18943.,  1815.,  1155.,  1697., 30177.,  2242.,\n",
      "         1666.,  1564.,   931.,  1065.,  2009.,  2203.,  1744.,  6716.,  2607.,\n",
      "         2449.,  1400.,  1238.,   830.,  1616.,  1648.,   913.,  1156.,  3193.,\n",
      "         1346., 20739.,  2126.,   664.,  2534.,  1381.,  1358.,  4436.,  1298.,\n",
      "         1915.,  1986., 24535.,  1047.,  2373.,  2055.,   632.,  3414.,   611.,\n",
      "          805.,  1873.,  1604., 82639.,   695.,  2576.,  8880.,  1342.,  1664.,\n",
      "         2198., 32946.,  5378.,  2013.,  1123.,  2371., 51051.,  3693.,  1445.,\n",
      "          710.], device='mps:0')\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8997e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.1024e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5334e+03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7711e+04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7413e+02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.4388e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.8257e+04, 0.0000e+00, 0.0000e+00, 8.0080e+03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.8608e+04, 1.9833e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.3690e+04, 2.7418e-06, 0.0000e+00, 0.0000e+00], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 9618.,  4843.,   706.,   985.,   803.,  2046.,  1037.,  2332.,  1627.,\n",
      "        25462.,   710.,  6700.,  2409.,   576.,  6490.,   978., 29401.,  1647.,\n",
      "          961.,  1831.,  2241.,  1974.,  2095., 32960., 30094.,  1131.,   854.,\n",
      "         2250., 42059.,  2321.,  9927.,  1583.,   569., 31082.,  2788.,  1132.,\n",
      "         1255.,  6244.,   692.,  2588., 13464.,   826.,  2105., 12421.,   895.,\n",
      "         2381.,  1004.,  8687., 38756.,   964.,  2066.,  1406., 22610.,  5753.,\n",
      "        26691.,  6328.,  1749.,  1186.,  1856.,  1048.,  1861.,  1752.,  2154.,\n",
      "        23043.], device='mps:0')\n",
      "tensor([ 9473.3975,  3435.6367,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 26302.1211,     0.0000,  3965.5339,\n",
      "            0.0000,     0.0000,  2095.3638,     0.0000, 28406.0977,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 30539.5391,\n",
      "        19652.8105,     0.0000,     0.0000,     0.0000, 29572.1797,     0.0000,\n",
      "         2865.6968,     0.0000,     0.0000, 26321.8945,     0.0000,     0.0000,\n",
      "            0.0000,  2053.7314,     0.0000,     0.0000, 15425.6641,     0.0000,\n",
      "            0.0000, 12057.7246,     0.0000,     0.0000,     0.0000,  8901.7256,\n",
      "        45039.7031,     0.0000,     0.0000,     0.0000, 21624.4805,  2211.4341,\n",
      "        18378.6250,  1230.7324,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 13953.5117], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1083.,  1730., 18224.,  1880.,  7515.,  1168.,   569.,  1315.,   834.,\n",
      "        30018.,   782.,  1918.,   733.,  2174., 29194.,  2923.,  2480.,  1833.,\n",
      "         4449., 33053.,  2743.,  2675.,   872., 63046., 34414.,   619.,  1366.,\n",
      "         1764.,  2097.,  6495.,  3821.,  5342.,  2137.,  2136., 13332.,  1169.,\n",
      "          826.,  2182.,  1867.,   710.,  1994.,  1743.,   746.,  1069.,  2022.,\n",
      "         1925.,  2492.,  2326.,  2166.,  2009.,  1928.,  4406.,   970., 62633.,\n",
      "         1708.,  3667.,  2150.,  1529., 73235.,   692.,  1232., 31871., 30073.,\n",
      "        22151.], device='mps:0')\n",
      "tensor([0.0000e+00, 0.0000e+00, 1.1399e+04, 0.0000e+00, 2.0897e+03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5285e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.1676e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.6703e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8540e+04,\n",
      "        2.7462e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4547e+02,\n",
      "        0.0000e+00, 2.6018e+02, 0.0000e+00, 0.0000e+00, 5.7029e+03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2726e+04,\n",
      "        0.0000e+00, 3.1270e+01, 0.0000e+00, 0.0000e+00, 8.1241e+04, 0.0000e+00,\n",
      "        0.0000e+00, 2.2099e+04, 2.7331e+04, 1.7166e+04], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([  991.,  5453.,   748.,  7858.,  2839., 23783.,  1674.,  2024.,  2181.,\n",
      "         1617.,  1125.,  1547.,   866.,   688.,  1883.,   775.,  2151.,  1691.,\n",
      "         3687.,  2010.,   889.,  2028.,  1145.,  1563.,  2236.,  2699.,  9577.,\n",
      "         1317., 27062., 16544.,   665., 12018.,   853.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,  7649.5220,     0.0000, 12634.1465,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  1712.5229,     0.0000, 26998.2188, 19936.3340,\n",
      "            0.0000, 11580.5918,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 6 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2150.,  1400.,  2203., 22610.,  1604.,  1298.,  2066., 25462.,  1856.,\n",
      "         1445.,  4449., 24535.,  1131.,  6328., 30177.,   710.,   576., 23783.,\n",
      "         3821.,  1831.,  2923.,  5342.,  1928.,  1833.,  2009.,  2576.,  3193.,\n",
      "          834.,   889.,  1564.,  1004.,  1648.,  2371.,  2024.,   826.,  1730.,\n",
      "         9927.,  2097., 20739.,   692.,  2009., 33053.,  6716.,  7858.,   619.,\n",
      "         1743.,  1358.,  2095.,   746.,   665.,  1366.,  2174.,  2839.,  3414.,\n",
      "         9618.,   826.,   706.,  2236.,  1617., 63046.,  2108., 16544.,   782.,\n",
      "        30018.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 22537.9414,     0.0000,     0.0000,\n",
      "            0.0000, 26731.1270,     0.0000,     0.0000,   411.5771, 25653.8066,\n",
      "            0.0000,  1091.9268, 30127.8867,     0.0000,     0.0000, 12888.8379,\n",
      "            0.0000,     0.0000,     0.0000,   284.1841,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         2589.7666,     0.0000, 26520.8867,     0.0000,     0.0000, 26781.1484,\n",
      "         4888.3867,  7799.9624,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         7449.6162,     0.0000,     0.0000,     0.0000,     0.0000, 68309.9219,\n",
      "            0.0000, 18730.4160,     0.0000, 27232.3574], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2137.,   961., 13464.,  3667.,   688.,  2181.,   991.,  7515.,  2699.,\n",
      "        13332.,  1925.,  1232.,  1186.,  1155.,  2480., 30073.,  8880.,  1315.,\n",
      "         2743., 62633.,  1583.,  1691., 38756., 32946.,   611.,   895.,  1616.,\n",
      "        31871.,  2242.,  1873., 82639.,  2607.,  2126.,  1547.,  6495.,   931.,\n",
      "         1994.,  2198., 29194.,  4406.,  1666.,  1974.,  1867.,   692.,  1156.,\n",
      "          853.,  1744.,  2028., 27062.,  1406.,  1697.,  1915., 22151., 26691.,\n",
      "         2022.,  1664.,  1169.,  2409.,  9577.,  2321.,  1951.,  1065.,  1125.,\n",
      "         2154.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000, 13489.3115,   993.7124,     0.0000,     0.0000,\n",
      "            0.0000,  1809.1582,     0.0000,  5206.7925,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 27326.7891,  8201.6660,     0.0000,\n",
      "            0.0000, 73226.8594,     0.0000,     0.0000, 45517.5820, 29127.3125,\n",
      "            0.0000,     0.0000,     0.0000, 21587.1777,     0.0000,     0.0000,\n",
      "        74810.8828,     0.0000,     0.0000,     0.0000,  2016.1030,     0.0000,\n",
      "            0.0000,     0.0000, 23038.6328,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        27324.1094,     0.0000,     0.0000,     0.0000, 16350.0244, 19041.6836,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  1965.9692,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([  830., 42059.,  1168., 34414., 23043.,   695.,  1083.,  2492.,  5453.,\n",
      "         1764., 12421.,  1708.,   985.,   978.,  2166.,  2046.,  6490.,   866.,\n",
      "         1381.,  1627.,   733., 31082.,   805.,  3687.,  1255.,  5378.,  2241.,\n",
      "         2332.,  2250.,  1123.,  4436.,  1749.,   872.,  1317.,  2136.,  1674.,\n",
      "         2675.,  1986.,  2449., 12018.,  1861.,  2381.,  1069.,  6700.,  1132.,\n",
      "        51051.,  2013.,  2326.,  5753.,  1048.,  1346., 29401.,  2182.,  1883.,\n",
      "         1342.,   964., 30094.,  1529.,  1145.,   913.,   748.,  2588., 32960.,\n",
      "         1880.], device='mps:0')\n",
      "tensor([    0.0000, 32903.4805,     0.0000, 25967.3164, 13679.5527,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 11612.3379,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2212.1206,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 26513.9023,     0.0000,     0.0000,\n",
      "            0.0000,  2435.5718,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "          100.2471,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 11786.0762,     0.0000,     0.0000,\n",
      "            0.0000,  2346.5640,     0.0000, 57258.3672,     0.0000,     0.0000,\n",
      "         2391.3481,     0.0000,     0.0000, 28658.8652,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 19835.9531,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 30375.6465,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2105.,   710.,  1918.,  2373.,   569.,  2055.,  2788., 73235.,  1647.,\n",
      "         3693., 18224.,   854.,  2151.,  8687.,   569.,   803.,  1238.,  2534.,\n",
      "          970.,  1983.,  1563.,  1752.,  1815., 18943.,  1047.,   775.,   664.,\n",
      "         6244.,   710.,  2010.,   632.,  1037.,  4843.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 77632.9141,     0.0000,     0.0000, 12087.5850,     0.0000,\n",
      "            0.0000,  7739.8086,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 17453.6406,\n",
      "            0.0000,     0.0000,     0.0000,  2432.2148,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  3267.4175], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 7 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2321.,  1617.,  2181., 18943.,   866.,  2576.,  1749.,  1730., 30073.,\n",
      "         1974.,  2009., 26691.,   830.,  1238., 82639., 13464.,  1861.,   692.,\n",
      "         1083.,  2923.,  1880.,  2028.,  4449.,  7858.,  1708.,   895.,  1529.,\n",
      "        32946.,   964.,  3414.,  6700.,  2136.,  1346.,  1604., 24535.,  1873.,\n",
      "        22610., 31082., 62633., 38756.,   688.,  1915.,   569.,  1168.,   826.,\n",
      "         4436.,  8687.,  1744., 30018.,  1951.,  1883.,  1697.,  1123.,  1831.,\n",
      "         2009.,  2250.,  2198.,  2066., 30177.,  1583.,  2182.,  5342.,  1647.,\n",
      "         2588.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 18237.5000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 26274.9531,     0.0000,     0.0000, 17731.2207,\n",
      "            0.0000,     0.0000, 75469.4609, 14081.6240,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,  7369.1348,\n",
      "            0.0000,     0.0000,     0.0000, 28521.1406,     0.0000,     0.0000,\n",
      "         2570.5188,     0.0000,     0.0000,     0.0000, 25951.6211,     0.0000,\n",
      "        22116.0645, 26520.7402, 68993.2109, 46456.1641,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,   260.8477,  7630.0156,     0.0000,\n",
      "        26344.8027,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 29987.6094,     0.0000,\n",
      "            0.0000,   424.0769,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2010., 29194.,  2492.,  2105., 63046.,   834.,  2150.,   913.,   695.,\n",
      "         2699.,  2046., 51051.,  3667.,  1004.,  1445.,  2373.,   970.,  1983.,\n",
      "         2022.,  5453.,  2137.,   710.,  1381.,  9618.,   782.,   803.,  1856.,\n",
      "          985.,  1037.,  2788.,  2326.,   619.,  2055.,  1131., 25462.,   889.,\n",
      "         2371., 18224.,   706.,  2480.,   611.,  1315.,  2449.,  1764.,  2203.,\n",
      "          748.,  1994.,  1752.,  2607.,  1132.,  1666.,   664.,  2241.,  1867.,\n",
      "         2097., 73235.,  2154.,  1547.,  3821.,  1563.,   733.,  4406.,  1674.,\n",
      "         2743.], device='mps:0')\n",
      "tensor([    0.0000, 22561.5684,     0.0000,     0.0000, 70188.6250,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 52560.4922,\n",
      "          842.4878,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,  7905.5454,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 25640.6758,     0.0000,\n",
      "            0.0000, 11333.4170,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 82132.4219,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([32960.,   991.,  1255.,  3693.,  2174.,  2242., 23783.,  6495.,  2534.,\n",
      "         1616.,  1564.,   710., 12018.,  1833.,  6716.,  2409., 13332.,  4843.,\n",
      "        42059.,   978.,  5378.,  7515.,  2839.,  1169.,  1400.,   665.,  1406.,\n",
      "         1065.,  1317.,   872.,   632.,  2236.,  1664.,  2024.,  2095.,  2013.,\n",
      "         1986.,  1232.,   826.,  1928.,  1691.,  1815.,  1342.,  1918.,  2151.,\n",
      "         1358.,   854.,   775., 29401.,  1298., 20739.,  1155., 31871., 30094.,\n",
      "         1627.,  5753.,  1069.,   576.,  1366.,  1648.,  6244.,   931.,  2108.,\n",
      "          710.], device='mps:0')\n",
      "tensor([30979.3125,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        13289.9902,  1009.3892,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        13531.9727,     0.0000,  3935.1738,     0.0000,  5512.7017,  3874.5566,\n",
      "        30857.6738,     0.0000,  1792.0269,  1978.4795,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        29681.9941,     0.0000, 29439.1504,     0.0000, 22571.7617, 18853.1367,\n",
      "            0.0000,  1548.3442,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         2442.3167,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([  961.,  9577., 27062.,  9927.,   746.,  2675.,   692., 16544.,  2126.,\n",
      "         8880.,  1925.,   805.,  1186.,  6490.,  3193.,   853.,   569., 12421.,\n",
      "         2332., 33053.,  1047.,  6328., 34414.,  3687.,  2381.,  1145.,  1156.,\n",
      "         1048.,  1125.,  1743., 22151.,  2166., 23043.], device='mps:0')\n",
      "tensor([    0.0000,  3146.6306, 25367.8652,  3630.2908,     0.0000,     0.0000,\n",
      "            0.0000, 17484.1895,     0.0000,  8313.2090,     0.0000,     0.0000,\n",
      "            0.0000,  3240.8982,     0.0000,     0.0000,     0.0000, 11853.4502,\n",
      "            0.0000, 26735.0254,     0.0000,  2770.3848, 27653.0332,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        17041.2891,     0.0000, 15050.2051], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 8 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 1168., 27062.,  1381.,  5753.,  1744., 13332.,  1048., 29401.,  3193.,\n",
      "        63046.,  1069.,  2242.,  1004.,  2321.,  2588.,  1915.,  9927.,  6716.,\n",
      "         1928.,  3821.,  8880.,  2699.,  2097.,  2022.,  1617., 51051.,  1155.,\n",
      "         2675.,  2009.,   706.,  2010.,   961.,  1145.,   895.,  1925.,  1131.,\n",
      "          803.,   748., 20739.,  2024.,  2046.,  1974.,   782.,   913., 12018.,\n",
      "          619.,   746.,  5378.,  2409.,  2923.,   569.,   664.,  4843.,   991.,\n",
      "        23043.,  6328., 30094.,  2105.,   576.,   854.,  1083., 25462.,  9618.,\n",
      "         1564.], device='mps:0')\n",
      "tensor([    0.0000, 25417.2402,     0.0000,  2357.3618,     0.0000,  5377.4644,\n",
      "            0.0000, 28465.7793,     0.0000, 67072.6328,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2198.3657,  4962.2285,\n",
      "            0.0000,     0.0000,  8443.5215,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 56453.5820,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 25513.4316,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 14337.1094,     0.0000,     0.0000,  3011.8718,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2752.0430,     0.0000,\n",
      "        14905.8154,   532.1704, 18880.6055,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 27313.1660,  8798.6953,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1664.,  2137.,  1861.,  1232.,  1815.,   710.,  1994.,  1831.,  5453.,\n",
      "        31871.,  5342.,  1691.,   569.,  1346.,  2250.,   611.,  2166.,  2028.,\n",
      "         2009.,  1880.,   692.,  1708.,   830., 13464.,  2492.,  1743., 12421.,\n",
      "         2743.,  1666.,  1918.,  1627.,   826.,   695.,  9577.,  6700.,  1583.,\n",
      "        26691.,  2326.,  2013.,   889.,  2332.,  1951.,  1986.,  1366.,  2381.,\n",
      "         1674.,  1764.,   805.,  1047.,  2203.,  1065.,   978.,  1037.,  4406.,\n",
      "         2055.,  1547., 24535.,  2534.,  2198.,  2151.,  1156.,  1358.,  1604.,\n",
      "         2154.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 22288.6133,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 14553.7129,\n",
      "            0.0000,     0.0000, 10877.9180,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  3426.3352,  1249.6475,     0.0000,\n",
      "        18988.9453,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,    69.3271,\n",
      "            0.0000,     0.0000, 26650.5352,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 3667., 22610.,  2373.,  1186., 32946.,  7858.,   775.,  1616.,   985.,\n",
      "         2150.,  1342.,  2174.,   688.,  1255., 82639.,  1730.,  1400., 30018.,\n",
      "         3693., 18943.,  2607., 22151.,  2371.,  1445.,  2066.,   853.,  2788.,\n",
      "         1406.,   931., 30073.,  2108.,  2136.,  1123.,  1749.,  1125.,  2839.,\n",
      "         1752.,  2449.,  6490.,  1856.,  2095.,   826.,  6244.,  1563., 31082.,\n",
      "         1317., 29194.,   710.,  1983.,   970.,  4449.,  1697.,   872.,  1883.,\n",
      "        73235.,  2576.,   964.,  2181.,  2126.,  1132.,  7515., 16544.,  2241.,\n",
      "        33053.], device='mps:0')\n",
      "tensor([  594.9839, 22044.5781,     0.0000,     0.0000, 28990.3262,  8393.6455,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 75898.8516,     0.0000,     0.0000, 26301.3848,\n",
      "            0.0000, 18235.3242,     0.0000, 17398.9746,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 26418.6621,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  2187.5435,     0.0000,     0.0000,     0.0000,\n",
      "         2345.4114,     0.0000, 27437.9395,     0.0000, 23794.6543,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        76872.0547,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         3244.1936, 18667.1797,     0.0000, 26122.7852], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 4436.,   834.,   710.,  2182., 23783.,   632.,   733., 42059., 34414.,\n",
      "         2480.,  1867.,  1298.,  1873.,  1648.,  2236.,  1833., 38756.,   692.,\n",
      "          665.,  1647.,  1529., 30177.,  8687., 32960., 18224., 62633.,  1238.,\n",
      "         3687.,  1169.,  3414.,   866.,  1315.,  6495.], device='mps:0')\n",
      "tensor([  822.9131,     0.0000,     0.0000,     0.0000, 13024.1699,     0.0000,\n",
      "            0.0000, 31125.9688, 26771.8770,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 46648.2656,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 27984.3691,  8515.6484, 29006.3574,\n",
      "        11378.8936, 73584.0156,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,   987.4829], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 9 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2743.,  2105.,   688.,  1974., 29194.,  2409.,  1238.,   695.,  1400.,\n",
      "         1730.,  2480.,  1232.,   775., 42059.,  1583., 25462., 12421., 73235.,\n",
      "          619.,  1617.,  2588.,   895.,  2166.,  1691.,   576.,  7515.,  1815.,\n",
      "         1915.,   692.,   853., 22610.,  6716., 23783.,  1752.,  2321.,  2154.,\n",
      "        27062.,   970.,  2055.,  1445.,  1131.,  1406.,  1037.,  1648.,  1983.,\n",
      "        20739.,  1255.,  1918.,  1132.,  1674., 26691.,  2371.,  2095.,  6495.,\n",
      "         1381., 30177.,  1366.,  1883.,  1298.,   834.,  1708.,   748.,  2492.,\n",
      "         2013.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000, 22557.9668,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 30884.2383,     0.0000, 26139.6973, 10401.7207, 76607.5703,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  3097.4595,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        22432.7168,  4888.0303, 14975.5195,     0.0000,     0.0000,     0.0000,\n",
      "        26568.0508,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 25061.5508,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 19124.1406,     0.0000,     0.0000,   755.3027,\n",
      "            0.0000, 28653.5762,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 5453., 30094.,   978.,  2151.,   854., 32946.,  2198.,  1047.,   782.,\n",
      "        34414., 18224., 31871.,  7858.,  3193., 32960.,  2066.,  2839.,  3414.,\n",
      "         2576., 16544.,  2137.,  1123.,  1564., 82639.,  2046.,  1744.,  1145.,\n",
      "         2675.,   866.,  1317.,   710.,  1155.,  1743.,  2241.,  1951.,  2174.,\n",
      "         1749.,  2923.,  1627.,   931.,   632.,   913.,  2182.,  2009.,  8687.,\n",
      "          805.,  2010.,  3687.,  1315.,  1604.,  1156.,  1664., 30073.,  1563.,\n",
      "         2024.,  1358.,  1861., 51051., 12018.,  1547.,  2028.,  2236.,  1856.,\n",
      "         1186.], device='mps:0')\n",
      "tensor([    0.0000, 18771.7031,     0.0000,     0.0000,     0.0000, 26733.6211,\n",
      "            0.0000,     0.0000,     0.0000, 26291.3809, 11471.8418, 21742.0234,\n",
      "         7883.2583,     0.0000, 29935.5098,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 19514.9277,     0.0000,     0.0000,     0.0000, 77513.1016,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  6798.0342,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 27655.7559,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 54043.2812, 11993.8281,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([  665.,  6244.,  1994.,  1048.,  1083.,  1169., 31082.,  4843.,  1342.,\n",
      "        29401.,  1168., 23043.,  2381., 38756.,   692.,  2126.,  2373.,  3693.,\n",
      "         1697.,  3667.,  2108.,  1666.,   991.,  1833.,   706.,   569.,  9577.,\n",
      "         4436.,  8880.,  2534.,  4449.,  1346.,  2009.,  2242.,   733.,  5342.,\n",
      "          985.,  1529.,   710.,  1928.,  6700.,   889.,  1004.,   746.,  6490.,\n",
      "         3821.,  1125.,  9618.,  2181., 22151.,  1647.,  1764.,   872.,  1616.,\n",
      "         5378.,  1831.,  2607.,   611.,  2250.,   826.,   710.,  5753., 13464.,\n",
      "         2449.], device='mps:0')\n",
      "tensor([    0.0000,  2958.0713,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        25639.0312,  2930.3687,     0.0000, 28571.1191,     0.0000, 15494.8379,\n",
      "            0.0000, 50295.4297,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  3034.7854,   569.2285,  7874.3472,     0.0000,\n",
      "          971.2334,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2208.5312,     0.0000,\n",
      "            0.0000,     0.0000,  2258.4199,     0.0000,     0.0000,  8682.9600,\n",
      "            0.0000, 15899.0762,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         2471.2109,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  2317.9873, 14850.9463,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([  803.,   961.,  1925.,  9927., 63046.,  6328., 24535.,   569.,  1867.,\n",
      "         1069.,  2150.,  2332.,   826.,  2097.,  1065.,  1986., 62633.,  2326.,\n",
      "        33053.,  2203., 13332.,  2136.,   830.,  2788.,  2699.,  4406.,  1880.,\n",
      "         1873.,   964.,   664.,  2022., 30018., 18943.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,  3267.9937, 67517.5156,  1296.3765,\n",
      "        25997.4570,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 68976.7266,     0.0000,\n",
      "        25785.8262,     0.0000,  5809.2905,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,   130.6409,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 24172.5508, 18172.3164], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 10 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 1123.,  3687.,  2108.,  9577., 18224.,  1616.,  1974.,  2010.,  1880.,\n",
      "        29401.,   748.,   834., 13464.,  1232.,  2151., 27062.,   710.,  2046.,\n",
      "         1381., 30073.,  1744.,  3693.,   692.,  1186.,   830.,  1445.,  1065.,\n",
      "         2174.,   913.,  1342.,  2743.,   746.,  2024.,  1666.,  2675.,  1856.,\n",
      "         1547., 62633.,  1925.,  1400.,  1156.,   692.,  1928.,  1915.,  2105.,\n",
      "          805.,  5342.,  2009., 29194.,  1647., 26691.,  2250.,  1951.,   872.,\n",
      "        30018.,   889.,   866.,  2028.,  1691., 18943.,  7858.,  1366.,  1131.,\n",
      "          576.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,  1886.0078, 11976.6152,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 28996.5332,     0.0000,     0.0000,\n",
      "        13776.2207,     0.0000,     0.0000, 26030.0215,     0.0000,     0.0000,\n",
      "            0.0000, 28432.5605,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 73023.7656,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,   267.7427,     0.0000,\n",
      "        22818.0234,     0.0000, 19070.9648,     0.0000,     0.0000,     0.0000,\n",
      "        25822.3164,     0.0000,     0.0000,     0.0000,     0.0000, 17516.6270,\n",
      "         8061.9180,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2182.,  1994., 32960.,  1627.,  2097.,  2492.,  1583.,   733.,  1169.,\n",
      "         1145.,  1833.,   991.,  6495.,   782., 31871.,  1918.,  2241., 32946.,\n",
      "         8687., 12018., 42059.,  1986.,  1004.,  1873.,   826., 22151.,  1749.,\n",
      "         1315.,  1358.,  6716.,  1048.,  2203.,  2381., 33053.,  2236.,  2788.,\n",
      "         4406.,  2923.,  2137.,   688.,  2126., 20739.,  2166.,   895., 23043.,\n",
      "        30094.,  2181.,  1069.,  3193.,  9927.,  6490.,   664.,  2022.,  1047.,\n",
      "         1648.,  9618.,  1764.,   710.,  2588., 16544., 24535.,   961.,  1238.,\n",
      "        13332.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000, 28904.2266,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "          749.6187,     0.0000, 22892.0898,     0.0000,     0.0000, 27841.7969,\n",
      "         7542.3950, 15163.6406, 31725.1094,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 16408.8086,     0.0000,     0.0000,     0.0000,  3598.6509,\n",
      "            0.0000,     0.0000,     0.0000, 27172.6992,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 24736.1328,\n",
      "            0.0000,     0.0000, 14321.3633, 19798.8164,     0.0000,     0.0000,\n",
      "            0.0000,  3964.8872,  2419.0967,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  8779.1162,     0.0000,     0.0000,     0.0000, 20079.9082,\n",
      "        26884.2578,     0.0000,     0.0000,  6295.9014], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1346.,  1674.,  1730.,  3821.,  2066.,  2839.,  2607., 25462.,   826.,\n",
      "         8880.,  1708.,  2154.,  2326.,  2242., 31082.,   569.,  1255.,  3414.,\n",
      "         4436.,  2198.,  1037.,  2480.,   619.,  1831.,  1697.,  1983.,  2699.,\n",
      "         2095.,  1563.,  2371.,   695., 34414.,   970., 38756.,  1743.,  2321.,\n",
      "         2013.,   569.,  4449.,   710.,  6328.,  7515., 82639.,  2150.,   964.,\n",
      "         1564.,  1298.,  2136.,  1168.,  1815.,  2449.,  1125.,   931.,  1617.,\n",
      "         1317.,   853.,  2332.,  2009.,  1664.,   611.,  2409.,   665., 73235.,\n",
      "         5753.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 26633.6465,     0.0000,  7348.1792,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 26307.6250,     0.0000,     0.0000,     0.0000,\n",
      "          229.4531,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 27578.1426,     0.0000, 46121.9648,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,   257.7153,     0.0000,  1829.2749,  1366.5635,\n",
      "        74891.5781,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 80280.8750,  1641.1733], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 5378.,  1861.,   854.,  1406.,  2534.,   632., 51051.,  1529.,  1883.,\n",
      "         1604., 30177.,  5453., 12421., 23783., 63046.,  1155., 22610.,  6700.,\n",
      "          775.,  1867.,  4843.,   978.,  2055.,   803.,   985.,  1132.,  1083.,\n",
      "          706.,  6244.,  1752.,  2576.,  3667.,  2373.], device='mps:0')\n",
      "tensor([ 2228.2280,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        53210.4766,     0.0000,     0.0000,     0.0000, 28420.8008,     0.0000,\n",
      "        10447.1426, 12169.5557, 68409.0547,     0.0000, 22649.3633,  1871.4751,\n",
      "            0.0000,     0.0000,  2570.1401,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2520.7390,     0.0000,\n",
      "            0.0000,   654.3843,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 11 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([  978.,  1674., 25462.,  1037.,   964.,  1255.,   611., 13464.,  2576.,\n",
      "         5378., 62633.,  1925.,   853.,  2198., 29401.,  2010.,   632., 33053.,\n",
      "         9618., 12421.,  5342.,  1406.,  1708., 30073.,  2151.,  1743.,   569.,\n",
      "         2236., 23783.,  1155.,  1563.,  2108.,  2181.,  6495.,  7858.,  2371.,\n",
      "         4436.,   746.,   692.,   805.,  1238.,  1627., 42059.,   576.,  1168.,\n",
      "          619.,  2492.,   931.,  1994.,  2241.,  1125., 73235.,   854., 34414.,\n",
      "         1833.,  4406.,  2137.,   803.,  2009.,   872., 32946.,  5453.,  3687.,\n",
      "        12018.], device='mps:0')\n",
      "tensor([0.0000e+00, 0.0000e+00, 2.5276e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.4398e+04, 0.0000e+00, 2.3985e+03, 7.1859e+04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.0011e+04, 0.0000e+00, 0.0000e+00, 2.5572e+04,\n",
      "        9.6177e+03, 1.1684e+04, 4.6735e+01, 0.0000e+00, 0.0000e+00, 2.7768e+04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3227e+04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3557e+03, 7.1388e+03, 0.0000e+00,\n",
      "        2.1236e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.9760e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2526e+04, 0.0000e+00, 2.8032e+04,\n",
      "        0.0000e+00, 3.3302e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.8854e+04, 0.0000e+00, 0.0000e+00, 1.3257e+04], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2449.,   826.,  2381.,   710.,  1873.,  1131.,  2675.,   834.,  6716.,\n",
      "         2022.,  1381.,   985.,  2024.,   970.,   775.,   913.,   826.,  1232.,\n",
      "        13332.,  1400.,  3821., 26691.,  8687., 18224.,   664., 31871., 31082.,\n",
      "         1647., 29194.,  1583.,   866.,   889.,  9927.,  1145.,  6244.,  3193.,\n",
      "         2154.,   782.,  2743., 30094.,   733., 23043., 16544.,  1749.,  1744.,\n",
      "         2242.,   991., 32960., 30018., 20739.,  2373.,  1983.,   692.,  1317.,\n",
      "         1764.,  1169.,  1346.,  2607.,   895.,  1915.,  4843.,   706., 27062.,\n",
      "        51051.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  4332.0601,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         6673.4180,     0.0000,     0.0000, 19181.4219,  6340.5620, 12259.5176,\n",
      "            0.0000, 23124.4492, 27850.9297,     0.0000, 23207.2656,     0.0000,\n",
      "            0.0000,     0.0000,  3448.1887,     0.0000,  1678.3281,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 18539.8359,     0.0000, 14288.5410,\n",
      "        20081.2773,     0.0000,     0.0000,     0.0000,     0.0000, 29650.1816,\n",
      "        26077.7656, 24776.5605,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         3573.8311,     0.0000, 25987.8477, 54771.9141], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2788.,  1342.,   695., 18943.,  1861.,  1856.,   688.,  1547.,  1315.,\n",
      "         1004.,  1048.,  1815.,  1617.,  1691.,  1358.,  8880.,  1928.,  1132.,\n",
      "         1666.,  7515.,   710.,  1883.,  3693.,  6328.,  1697.,  1616.,  4449.,\n",
      "         1083.,  1974.,  1730.,  2326.,  3667.,  1529.,  3414.,  2009.,  2174.,\n",
      "         6490.,  1752.,   961., 30177.,  1880.,  2332.,  2203.,  2588.,  2699.,\n",
      "        22151.,  2166., 22610.,  5753., 38756.,  1069.,  2097.,  1918.,  1564.,\n",
      "         2028.,  1047., 82639.,  2250.,   710., 63046.,  1986.,  2013.,  2105.,\n",
      "        24535.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 18584.9199,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  8505.7383,     0.0000,     0.0000,\n",
      "            0.0000,  1853.7656,     0.0000,     0.0000,     0.0000,  1344.9966,\n",
      "            0.0000,     0.0000,   460.6235,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,   152.5405,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         2765.0806,     0.0000,     0.0000, 28529.9844,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 17123.9219,     0.0000, 22259.0273,\n",
      "         2252.6196, 46353.7656,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 75920.8984,     0.0000,     0.0000, 68156.8125,\n",
      "            0.0000,     0.0000,     0.0000, 26566.3066], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([2534., 1065., 2126., 6700., 1867., 1648., 2839., 2321., 1664., 2923.,\n",
      "        2182., 2066., 1366.,  665., 2136., 1123., 2095., 2480., 1604., 1951.,\n",
      "         748., 2046., 9577., 1298., 2409.,  830., 1445., 1186., 1156., 2055.,\n",
      "        1831.,  569., 2150.], device='mps:0')\n",
      "tensor([   0.0000,    0.0000,    0.0000, 2918.1592,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000, 2276.7207,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 12 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 1037.,  2024.,  2105.,  2371.,  1232., 31082.,   978.,   985.,  2009.,\n",
      "         2449.,  1125., 73235., 27062.,  3667.,  1743.,   665.,  1564., 12421.,\n",
      "          805.,  2203., 30073., 25462.,  1815.,  1083.,   733.,  1764.,   970.,\n",
      "         2788., 32960.,  2022., 16544.,  2198.,  1547., 23043.,   695.,  4843.,\n",
      "          710.,  1298.,  1697.,  1604.,  3414.,   853.,  1648.,  5753.,  4436.,\n",
      "         2174.,  3193., 51051., 34414.,  2321., 33053.,  2480.,  1974.,  2097.,\n",
      "         2373.,   866.,   889.,  6700.,   964.,  1563.,  2332.,   664.,  3687.,\n",
      "          834.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 25869.5918,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 77629.5781,\n",
      "        24731.8301,   545.5752,     0.0000,     0.0000,     0.0000, 10720.9746,\n",
      "            0.0000,     0.0000, 26463.2812, 26615.4590,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 29502.0938,     0.0000,\n",
      "        20390.1699,     0.0000,     0.0000, 14907.2480,     0.0000,  3070.6196,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  2753.7578,  1254.9126,     0.0000,     0.0000, 54764.3359,\n",
      "        26662.9355,     0.0000, 25314.0547,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,  2615.1111,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([18943.,   913.,  1617.,  5342.,  1691., 24535.,   872.,  1951.,  1047.,\n",
      "         2381.,  2923., 42059.,   854.,  2409.,   569.,   961., 31871.,  1833.,\n",
      "         1583.,   692.,  1342.,  1861., 38756.,  2137., 22151.,  1873.,  1647.,\n",
      "          746.,  1048.,   991.,  1132.,  1983.,  2010.,  1674.,  2151.,  1445.,\n",
      "         1400.,  1666.,  9927.,  2534.,   826.,  1156.,   692.,  2839.,  2236.,\n",
      "         1616.,  1131., 63046.,  2576., 32946.,  1366.,  1255.,  1831.,  1155.,\n",
      "         4406.,  1186.,  1994.,  2013.,  6716.,  2699., 20739., 22610.,  2241.,\n",
      "         1664.], device='mps:0')\n",
      "tensor([18284.2637,     0.0000,     0.0000,   514.9368,     0.0000, 25509.3438,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 31762.0215,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 19765.6562,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 47049.7461,     0.0000,\n",
      "        16454.2969,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  3465.0564,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 66333.3281,\n",
      "            0.0000, 28037.9023,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  4657.6250,     0.0000,\n",
      "        25906.5742, 21325.9375,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2126.,   710., 13332.,  2154.,  1069.,  2066.,  1928.,  1168.,  8687.,\n",
      "         2150.,  7515., 30094.,  9618.,  1856.,   775.,  6490.,  1529.,  1381.,\n",
      "         1406.,   688.,  2136.,  2166.,   895.,  2675.,   782., 23783.,   931.,\n",
      "         2588.,  1358.,   830.,   706.,  2607.,  1883.,  3821.,   632.,  1752.,\n",
      "         1730., 13464.,  9577.,  6495.,  5378., 29401.,  4449.,  1317.,  2182.,\n",
      "         1145.,   710.,  1238.,  1918.,  1915.,  2009.,  1749.,  3693.,  1925.,\n",
      "         7858.,  8880.,   569.,   576.,   611., 30177., 62633.,  1867.,  2181.,\n",
      "         2095.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,  5765.5415,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,  7415.6094,     0.0000,  2215.3787, 19826.3223,\n",
      "         8859.8145,     0.0000,     0.0000,  2101.5635,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 13071.2109,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 16148.7861,  1837.5098,  1369.3894,  1725.2627, 30280.1719,\n",
      "           97.0342,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         7785.2432,  7463.6689,     0.0000,     0.0000,     0.0000, 30612.5664,\n",
      "        71367.6719,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1708.,  1004., 12018.,   748., 29194.,  1627.,  1065., 30018., 26691.,\n",
      "         2326.,  2046.,  6244.,  1123.,  2242.,  1880., 18224.,   803.,  1346.,\n",
      "         6328.,  1315., 82639.,  2743.,   826.,  2250.,  1744.,  2055.,  2492.,\n",
      "          619.,  1169.,  2108.,  2028.,  1986.,  5453.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000, 12234.5430,     0.0000, 23649.4922,     0.0000,\n",
      "            0.0000, 24206.4375, 18434.9453,     0.0000,     0.0000,  1053.9136,\n",
      "            0.0000,     0.0000,     0.0000, 11596.2168,     0.0000,     0.0000,\n",
      "          756.6787,     0.0000, 76369.7969,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 13 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 5378.,  1764.,  1708.,  6490.,  2409.,   569.,  6716., 31082.,  2449.,\n",
      "        20739., 30177.,   665.,   853., 22610.,  1925.,  5753.,   931.,  1125.,\n",
      "        24535.,  1232.,  2108.,  2154.,  1647.,   710.,  7858.,  2242.,  2055.,\n",
      "         1880.,  1317.,  5342.,  1445.,  1730.,  1918.,   611.,  1743.,  2203.,\n",
      "         1583.,  1298.,  2576.,  3821.,  3414.,  1156.,  2839.,   826.,  1752.,\n",
      "         1037.,  2010.,  2028.,  5453.,  2097.,  2022.,   632.,   803.,  2675.,\n",
      "         3693.,  2009.,  2788.,   830.,  7515.,  2534.,  2332.,  6495.,  2166.,\n",
      "         1983.], device='mps:0')\n",
      "tensor([ 2965.8809,     0.0000,     0.0000,  3425.9067,     0.0000,     0.0000,\n",
      "         4004.3779, 25927.3125,     0.0000, 29024.1777, 31338.7773,     0.0000,\n",
      "            0.0000, 23070.1172,     0.0000,  1572.3369,     0.0000,     0.0000,\n",
      "        26775.7188,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         7522.3960,     0.0000,     0.0000,     0.0000,     0.0000,   149.7075,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  1494.2979,     0.0000,\n",
      "            0.0000,  1440.3528,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2371.,  1083.,  3193.,  1065.,   710.,  1342.,   706.,  1145.,  1666.,\n",
      "          834.,   866.,  4436.,   985.,  2492.,  1616.,   964., 29401.,  1664.,\n",
      "          889.,  9577.,  4449., 18943., 31871.,  1169.,  2480.,  1406.,  1915.,\n",
      "          688.,  8880.,  1238.,  1674.,  1951., 82639.,  1547., 33053.,  2046.,\n",
      "        32960., 34414.,  1168.,   569.,   854.,  1749.,  1617.,  2236.,   733.,\n",
      "          692.,  3687.,  2699.,  1004.,  1648.,  1123.,   746.,  1986., 51051.,\n",
      "          748.,  1155.,  6700.,  1131.,  6244.,   805.,  1381.,  1861., 30018.,\n",
      "         2373.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,   345.9160,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 29226.5273,     0.0000,\n",
      "            0.0000,  2484.5637,    85.2778, 18898.3379, 22553.7266,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  7907.3232,     0.0000,\n",
      "            0.0000,     0.0000, 75233.0391,     0.0000, 25422.0508,     0.0000,\n",
      "        29669.6504, 28396.1875,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 56025.5195,\n",
      "            0.0000,     0.0000,  2740.3735,     0.0000,  2234.8250,     0.0000,\n",
      "            0.0000,     0.0000, 25856.0879,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2105.,  1744.,  1315., 12018.,   710., 38756.,  1831.,  1856.,   692.,\n",
      "         2181.,  9927.,  1366.,  1069.,  1873., 32946.,  1833.,  3667.,  2151.,\n",
      "         1994.,  2588.,  1048.,  2743.,  2126.,   619.,  1255.,  1604., 23783.,\n",
      "          991.,  1697., 16544.,  1132.,  9618.,   775.,  1691., 62633.,   895.,\n",
      "         1358.,  4406.,  2326.,  1815., 25462.,  2013.,   913., 13332.,  1346.,\n",
      "          576.,   664.,  1883.,  1400., 23043.,  1928.,   695.,   826.,  1564.,\n",
      "          978.,  2381.,  2250.,  1047.,  1867., 30094., 63046.,  1627.,  2198.,\n",
      "         2150.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 12808.1758,     0.0000, 47302.8945,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,  2690.3374,     0.0000,\n",
      "            0.0000,     0.0000, 29632.7539,     0.0000,   528.8037,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 12910.8594,     0.0000,     0.0000, 19136.1855,\n",
      "            0.0000,  8722.1055,     0.0000,     0.0000, 70337.5078,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 25347.0508,     0.0000,\n",
      "            0.0000,  6423.2383,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000, 14845.7344,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 18247.6797,\n",
      "        65866.6016,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2923.,  2241.,   970., 27062., 12421.,   961.,  2095., 30073., 42059.,\n",
      "        29194., 18224., 22151.,  2137.,  2136.,  2321.,  2066.,   872., 13464.,\n",
      "         1563.,  2009.,  1186.,  1529., 73235.,  2174.,  2182.,  2024., 26691.,\n",
      "         4843.,  2607.,  6328.,   782.,  1974.,  8687.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000, 25494.3535, 11373.0684,     0.0000,\n",
      "            0.0000, 26375.7520, 31123.9688, 22085.9766, 11083.1318, 16324.9102,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 14458.5098,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000, 82001.2812,     0.0000,\n",
      "            0.0000,     0.0000, 18460.3066,  3179.4536,     0.0000,  1134.9272,\n",
      "            0.0000,     0.0000,  7321.6880], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 14 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([  970.,  2492.,  1915.,  1749.,   665., 13464.,  1132., 16544., 23043.,\n",
      "          706., 63046.,  1406.,  1764.,   830., 31082.,   782.,  2534.,  3667.,\n",
      "         2675.,  2013.,  1648.,  2108.,  2373., 34414.,  1986.,  9577.,  1744.,\n",
      "         1994.,  6490.,  4436.,  9927.,  1564.,  1255., 24535.,  1951., 29194.,\n",
      "         2055.,  1708.,  1815.,   991.,  2236., 30177., 33053.,  1400.,   834.,\n",
      "         2332.,   803.,  2923.,   805.,  1083., 73235., 32946.,  2607.,  1928.,\n",
      "         1730.,  7858.,  1563.,  2046.,  1831.,  2241.,  2024.,  1833.,  1037.,\n",
      "          710.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 13855.1797,\n",
      "            0.0000, 18314.3066, 14146.9355,     0.0000, 67715.9453,     0.0000,\n",
      "            0.0000,     0.0000, 26763.7559,     0.0000,     0.0000,   416.6401,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 28121.3691,\n",
      "            0.0000,  2051.5039,     0.0000,     0.0000,  2966.9856,   604.2632,\n",
      "         3531.9036,     0.0000,     0.0000, 26069.3652,     0.0000, 23424.8711,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000, 28821.5234,\n",
      "        25847.5273,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 79540.7266, 28841.4082,     0.0000,     0.0000,\n",
      "            0.0000,  7942.5752,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 4449., 26691., 62633.,  1317.,  1883.,  2136.,  1666.,  1155.,  1856.,\n",
      "        32960.,  2788.,  2174.,   961.,   611.,  2242.,   978.,  1647.,  2326.,\n",
      "         2198.,  8687.,   853., 27062.,  1298.,   692.,  5453.,   688.,  2095.,\n",
      "         2181.,  1664.,  2028.,  2097., 12018., 29401.,  1752.,   632.,  1123.,\n",
      "        23783.,  2154.,  6244., 30094.,  1048.,  1168.,  1065.,  1616.,  2203.,\n",
      "         2166.,  1342.,  1880.,  1547., 38756.,  2010.,   695.,   710.,  6328.,\n",
      "         1529.,  1983., 82639.,  2371.,   964.,  2105.,  3687., 22151.,  1918.,\n",
      "         6700.], device='mps:0')\n",
      "tensor([0.0000e+00, 1.8738e+04, 7.1117e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9476e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 9.1738e+03, 0.0000e+00, 2.5499e+04, 0.0000e+00, 0.0000e+00,\n",
      "        4.2174e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.3187e+04, 2.9577e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.2838e+04, 0.0000e+00, 2.5559e+03, 1.8952e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.7849e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2753e+03,\n",
      "        0.0000e+00, 0.0000e+00, 7.4507e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.7108e+04, 0.0000e+00, 1.5537e+03], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([30073.,  8880.,  1697.,  6716., 18224.,  1925.,  7515.,   931.,  1861.,\n",
      "          576., 13332.,  2449.,   733.,   826.,  1232., 18943.,  1627.,   569.,\n",
      "          889.,  2137.,  1145., 31871., 42059.,   872.,  6495.,  3821.,   826.,\n",
      "         2009.,  1691.,   569.,  5378.,  4843.,  1131.,   775.,  5753.,  2150.,\n",
      "         4406.,   619.,  2743.,  2381.,   746.,  2321.,  1238.,  3414.,   692.,\n",
      "         1617.,  1366.,  1346.,  1315.,  2576.,  2182., 25462.,  1125.,  2151.,\n",
      "         1867.,  2009.,  1974.,  1381.,   895.,   866.,  2588.,  5342.,  1169.,\n",
      "        22610.], device='mps:0')\n",
      "tensor([27313.4570,  8079.1665,     0.0000,  4221.7090, 11787.8867,     0.0000,\n",
      "         1707.3896,     0.0000,     0.0000,     0.0000,  6225.7212,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 19175.9766,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 21876.9062, 32946.7188,     0.0000,\n",
      "          895.3140,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "         1335.1216,  3208.8652,     0.0000,     0.0000,  2112.5024,     0.0000,\n",
      "          706.7454,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000, 27267.6543,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,   394.3828,     0.0000, 23401.8535], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1743.,  1445.,  1604.,   854.,  3693.,  2022.,  1583., 12421.,   985.,\n",
      "         3193.,  1186.,  2409.,  2066., 51051., 30018.,  2699.,  2839., 20739.,\n",
      "         1674.,  1004.,  2250.,  1069.,  1358.,  2480.,   913.,  1873.,  1047.,\n",
      "         9618.,   710.,   664.,   748.,  1156.,  2126.], device='mps:0')\n",
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4713e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.1222e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.3920e+04, 2.4616e+04, 0.0000e+00, 0.0000e+00, 2.5790e+04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0012e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n",
      "Epoch 15 - Train loss: inf - Val loss: inf - ES count: 0\n",
      "tensor([ 2250.,  1928.,  9577.,  2241.,  1994.,  2151., 20739.,  2013.,  1833.,\n",
      "          826.,  1186.,  8687., 38756.,  1743.,  9927.,  1131.,  1697.,  1647.,\n",
      "         2022.,  6244.,  2055.,   853.,  1232.,  2024.,  1083.,   569.,  1406.,\n",
      "         2607.,  1298.,  1616.,  1951.,  2046., 26691.,  1069.,   805.,  2166.,\n",
      "          931.,  2182.,  1156.,  1123.,   854.,  3693., 24535.,  1666.,  1604.,\n",
      "         5378., 16544.,  2576.,  2010., 51051.,   895.,  2095.,  2136.,  1342.,\n",
      "         1047.,  9618.,  1883.,  2449.,   576.,   746.,   710.,  1831.,  5342.,\n",
      "          826.], device='mps:0')\n",
      "tensor([    0.0000,     0.0000,  1739.8389,     0.0000,     0.0000,     0.0000,\n",
      "        28678.8027,     0.0000,     0.0000,     0.0000,     0.0000,  8990.7461,\n",
      "        49990.8047,     0.0000,  3583.0901,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  2030.6978,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000, 19422.1270,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "        24826.0469,     0.0000,     0.0000,  1480.5498, 18026.8301,     0.0000,\n",
      "            0.0000, 54966.7852,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,  9259.2090,     0.0000,     0.0000,     0.0000,     0.0000,\n",
      "            0.0000,     0.0000,   973.0879,     0.0000], device='mps:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m nowcast_pnn \u001b[38;5;241m=\u001b[39m ForecastPNN(past_units\u001b[38;5;241m=\u001b[39mPAST_UNITS)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#nowcast_pnn = PNNSumDaily(past_units=PAST_UNITS, max_delay=MAX_DELAY)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnowcast_pnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnll\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m## Load best set of weights on test/validation set\u001b[39;00m\n\u001b[1;32m     11\u001b[0m nowcast_pnn\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights/weights-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPAST_UNITS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mWEEKS\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-rec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39mRANDOM_SPLIT\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-dow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/src/forecastpnn/utils/train_utils.py:79\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, train_loader, val_loader, early_stopper, loss_fct, device, dow, num_obs)\u001b[0m\n\u001b[1;32m     77\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mat, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     80\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_obs:\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/.fpnn_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/.fpnn_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/.fpnn_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/.fpnn_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/src/forecastpnn/torch_utils/dataset.py:82\u001b[0m, in \u001b[0;36mReportingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m     dow_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(dow_val)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     81\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(array)\n\u001b[0;32m---> 82\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(torch\u001b[38;5;241m.\u001b[39mtensor([target])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdow:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from forecastpnn.utils.train_utils import train, EarlyStopper\n",
    "from forecastpnn.models.forecastpnn import ForecastPNN\n",
    "set_seeds(RANDOM_SEED)\n",
    "\n",
    "regen_data() # reset samplers so each training run is reproducible\n",
    "early_stopper = EarlyStopper(patience=30, past_units=PAST_UNITS, weeks=WEEKS, future_obs=0)\n",
    "nowcast_pnn = ForecastPNN(past_units=PAST_UNITS)\n",
    "#nowcast_pnn = PNNSumDaily(past_units=PAST_UNITS, max_delay=MAX_DELAY)\n",
    "train(nowcast_pnn, num_epochs=500, train_loader=train_loader, val_loader=val_loader, early_stopper=early_stopper, loss_fct=\"nll\", device = DEVICE)\n",
    "## Load best set of weights on test/validation set\n",
    "nowcast_pnn.load_state_dict(torch.load(f\".weights/weights-{PAST_UNITS}-{'week' if WEEKS else 'day'}{'-rec' if not RANDOM_SPLIT else ''}{'-dow' if False else ''}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29905.],\n",
      "        [25462.],\n",
      "        [31871.],\n",
      "        [32946.],\n",
      "        [30177.],\n",
      "        [20739.],\n",
      "        [15614.],\n",
      "        [14169.],\n",
      "        [12008.],\n",
      "        [ 7858.],\n",
      "        [ 4843.],\n",
      "        [ 4449.],\n",
      "        [ 3693.],\n",
      "        [ 2839.],\n",
      "        [ 1925.],\n",
      "        [ 1604.],\n",
      "        [ 1400.],\n",
      "        [ 1131.],\n",
      "        [  611.],\n",
      "        [  803.],\n",
      "        [  853.],\n",
      "        [  695.],\n",
      "        [  746.],\n",
      "        [  680.],\n",
      "        [  710.],\n",
      "        [  757.],\n",
      "        [  854.],\n",
      "        [  706.],\n",
      "        [  733.],\n",
      "        [  775.],\n",
      "        [  864.],\n",
      "        [  961.],\n",
      "        [  957.],\n",
      "        [  931.],\n",
      "        [ 1029.],\n",
      "        [ 1186.],\n",
      "        [ 1238.],\n",
      "        [ 1346.],\n",
      "        [ 1342.],\n",
      "        [ 1155.],\n",
      "        [  978.],\n",
      "        [ 1180.],\n",
      "        [ 1730.],\n",
      "        [ 2108.],\n",
      "        [ 2492.],\n",
      "        [ 3193.],\n",
      "        [ 3821.],\n",
      "        [ 5453.],\n",
      "        [ 6328.],\n",
      "        [ 6244.],\n",
      "        [ 7515.],\n",
      "        [ 9927.],\n",
      "        [13332.],\n",
      "        [18742.],\n",
      "        [23043.],\n",
      "        [30094.],\n",
      "        [33053.],\n",
      "        [32960.],\n",
      "        [29401.],\n",
      "        [24535.],\n",
      "        [22700.],\n",
      "        [16544.],\n",
      "        [12018.],\n",
      "        [ 8687.],\n",
      "        [ 6716.],\n",
      "        [ 5378.],\n",
      "        [ 4436.],\n",
      "        [ 3626.],\n",
      "        [ 2789.],\n",
      "        [ 2534.],\n",
      "        [ 2240.],\n",
      "        [ 1928.],\n",
      "        [ 1708.],\n",
      "        [ 1664.],\n",
      "        [ 1649.],\n",
      "        [ 1567.],\n",
      "        [ 1583.],\n",
      "        [ 1666.],\n",
      "        [ 1707.],\n",
      "        [ 1691.],\n",
      "        [ 1764.],\n",
      "        [ 1911.],\n",
      "        [ 2010.],\n",
      "        [ 1867.],\n",
      "        [ 1918.],\n",
      "        [ 2028.],\n",
      "        [ 1974.],\n",
      "        [ 2013.],\n",
      "        [ 2022.],\n",
      "        [ 2198.],\n",
      "        [ 2381.],\n",
      "        [ 2326.],\n",
      "        [ 2588.],\n",
      "        [ 4260.],\n",
      "        [ 7393.],\n",
      "        [10219.],\n",
      "        [17192.],\n",
      "        [23783.],\n",
      "        [31143.],\n",
      "        [34414.],\n",
      "        [42059.],\n",
      "        [53583.],\n",
      "        [68115.],\n",
      "        [77947.],\n",
      "        [82639.],\n",
      "        [73235.],\n",
      "        [62633.],\n",
      "        [70597.],\n",
      "        [63046.],\n",
      "        [57944.],\n",
      "        [51051.],\n",
      "        [38756.],\n",
      "        [26830.],\n",
      "        [19285.],\n",
      "        [13464.],\n",
      "        [ 9618.],\n",
      "        [ 7523.],\n",
      "        [ 5753.],\n",
      "        [ 3667.],\n",
      "        [ 2788.],\n",
      "        [ 2009.],\n",
      "        [ 2182.],\n",
      "        [ 2126.],\n",
      "        [ 1865.],\n",
      "        [ 1617.],\n",
      "        [ 1752.],\n",
      "        [ 1489.],\n",
      "        [ 1315.],\n",
      "        [ 1389.],\n",
      "        [ 1232.],\n",
      "        [ 1796.],\n",
      "        [ 1983.],\n",
      "        [ 2055.],\n",
      "        [ 2137.],\n",
      "        [ 2373.],\n",
      "        [ 2436.],\n",
      "        [ 2250.],\n",
      "        [ 2743.],\n",
      "        [ 3414.],\n",
      "        [ 3687.],\n",
      "        [ 4406.],\n",
      "        [ 5342.],\n",
      "        [ 6495.],\n",
      "        [ 6700.],\n",
      "        [ 6490.],\n",
      "        [ 9577.],\n",
      "        [13976.],\n",
      "        [16027.],\n",
      "        [18224.],\n",
      "        [20563.],\n",
      "        [22151.],\n",
      "        [26691.],\n",
      "        [29194.],\n",
      "        [30018.],\n",
      "        [31082.],\n",
      "        [30073.],\n",
      "        [29853.],\n",
      "        [27062.],\n",
      "        [26327.],\n",
      "        [22610.],\n",
      "        [18943.],\n",
      "        [15590.],\n",
      "        [12421.],\n",
      "        [ 8880.],\n",
      "        [ 6115.],\n",
      "        [ 4266.],\n",
      "        [ 2789.],\n",
      "        [ 2321.],\n",
      "        [ 1385.],\n",
      "        [ 1317.],\n",
      "        [ 1048.],\n",
      "        [ 1083.],\n",
      "        [  964.],\n",
      "        [  895.],\n",
      "        [  710.],\n",
      "        [  805.],\n",
      "        [  834.],\n",
      "        [  826.],\n",
      "        [  866.],\n",
      "        [  889.],\n",
      "        [  830.],\n",
      "        [  991.],\n",
      "        [ 1145.],\n",
      "        [ 1004.],\n",
      "        [ 1125.],\n",
      "        [ 1132.],\n",
      "        [ 1445.],\n",
      "        [ 1829.],\n",
      "        [ 1714.],\n",
      "        [ 1873.],\n",
      "        [ 2009.],\n",
      "        [ 2046.],\n",
      "        [ 2166.],\n",
      "        [ 2242.],\n",
      "        [ 2150.],\n",
      "        [ 1951.],\n",
      "        [ 1880.],\n",
      "        [ 2097.],\n",
      "        [ 2332.],\n",
      "        [ 2258.],\n",
      "        [ 2236.],\n",
      "        [ 2551.],\n",
      "        [ 2828.],\n",
      "        [ 2923.],\n",
      "        [ 2937.],\n",
      "        [ 2449.],\n",
      "        [ 2576.],\n",
      "        [ 2699.],\n",
      "        [ 2607.],\n",
      "        [ 2480.],\n",
      "        [ 2203.],\n",
      "        [ 2241.],\n",
      "        [ 1994.],\n",
      "        [ 1856.],\n",
      "        [ 1366.],\n",
      "        [ 1408.],\n",
      "        [ 1358.],\n",
      "        [ 1169.],\n",
      "        [ 1293.],\n",
      "        [ 1156.],\n",
      "        [  953.],\n",
      "        [  782.],\n",
      "        [  826.],\n",
      "        [  672.],\n",
      "        [  569.],\n",
      "        [  589.],\n",
      "        [  532.],\n",
      "        [  576.],\n",
      "        [  619.],\n",
      "        [  665.],\n",
      "        [  603.],\n",
      "        [  805.],\n",
      "        [  985.],\n",
      "        [ 1065.],\n",
      "        [ 1406.],\n",
      "        [ 1610.],\n",
      "        [ 1616.],\n",
      "        [ 1833.],\n",
      "        [ 1831.],\n",
      "        [ 1915.],\n",
      "        [ 1648.],\n",
      "        [ 1647.],\n",
      "        [ 1743.],\n",
      "        [ 1547.],\n",
      "        [ 1563.],\n",
      "        [ 1749.],\n",
      "        [ 1697.],\n",
      "        [ 1674.],\n",
      "        [ 1331.],\n",
      "        [ 1298.],\n",
      "        [ 1744.],\n",
      "        [ 2151.],\n",
      "        [ 2675.],\n",
      "        [ 2425.],\n",
      "        [ 2551.],\n",
      "        [ 2095.],\n",
      "        [ 2105.],\n",
      "        [ 2181.],\n",
      "        [ 2174.],\n",
      "        [ 2136.],\n",
      "        [ 2154.],\n",
      "        [ 2024.],\n",
      "        [ 1861.],\n",
      "        [ 2104.],\n",
      "        [ 2066.],\n",
      "        [ 1883.],\n",
      "        [ 1627.],\n",
      "        [ 1986.],\n",
      "        [ 1815.],\n",
      "        [ 1529.],\n",
      "        [ 1210.],\n",
      "        [ 1028.],\n",
      "        [ 1037.],\n",
      "        [ 1150.],\n",
      "        [ 1047.],\n",
      "        [  970.],\n",
      "        [  791.],\n",
      "        [  602.],\n",
      "        [  730.],\n",
      "        [  664.],\n",
      "        [  632.],\n",
      "        [  569.],\n",
      "        [  692.],\n",
      "        [  688.],\n",
      "        [  692.],\n",
      "        [  588.],\n",
      "        [  710.],\n",
      "        [  748.],\n",
      "        [  872.],\n",
      "        [  906.],\n",
      "        [  913.],\n",
      "        [ 1123.],\n",
      "        [ 1069.],\n",
      "        [ 1168.],\n",
      "        [ 1255.],\n",
      "        [ 1381.],\n",
      "        [ 1564.],\n",
      "        [ 1807.],\n",
      "        [ 2020.],\n",
      "        [ 2409.],\n",
      "        [ 2371.],\n",
      "        [ 2771.],\n",
      "        [ 4378.],\n",
      "        [ 5469.],\n",
      "        [ 7533.],\n",
      "        [10359.],\n",
      "        [13144.],\n",
      "        [16484.],\n",
      "        [18542.],\n",
      "        [20591.],\n",
      "        [19279.],\n",
      "        [21460.],\n",
      "        [25437.],\n",
      "        [28909.],\n",
      "        [32906.],\n",
      "        [36458.],\n",
      "        [39912.],\n",
      "        [41195.],\n",
      "        [44089.],\n",
      "        [43614.],\n",
      "        [46440.],\n",
      "        [43617.],\n",
      "        [34513.],\n",
      "        [25710.],\n",
      "        [19172.],\n",
      "        [16199.],\n",
      "        [12629.],\n",
      "        [10774.],\n",
      "        [ 6636.],\n",
      "        [ 4759.],\n",
      "        [ 3677.],\n",
      "        [ 3439.],\n",
      "        [ 2770.],\n",
      "        [ 2642.],\n",
      "        [ 2296.],\n",
      "        [ 2052.],\n",
      "        [ 2036.],\n",
      "        [ 1962.],\n",
      "        [ 2458.],\n",
      "        [ 2451.],\n",
      "        [ 1982.],\n",
      "        [ 2382.],\n",
      "        [ 2421.],\n",
      "        [ 2532.],\n",
      "        [ 2381.],\n",
      "        [ 2694.],\n",
      "        [ 2710.],\n",
      "        [ 2584.],\n",
      "        [ 3060.],\n",
      "        [ 3097.],\n",
      "        [ 3494.],\n",
      "        [ 3836.],\n",
      "        [ 3765.],\n",
      "        [ 4209.],\n",
      "        [ 6845.],\n",
      "        [ 9901.],\n",
      "        [13398.],\n",
      "        [17075.],\n",
      "        [19266.],\n",
      "        [24395.],\n",
      "        [27237.],\n",
      "        [23271.],\n",
      "        [23137.],\n",
      "        [24626.],\n",
      "        [22270.],\n",
      "        [15071.],\n",
      "        [13486.],\n",
      "        [12498.],\n",
      "        [11618.],\n",
      "        [11732.],\n",
      "        [10898.],\n",
      "        [10232.],\n",
      "        [ 9099.],\n",
      "        [ 7939.],\n",
      "        [ 5825.],\n",
      "        [ 4528.],\n",
      "        [ 4705.],\n",
      "        [ 4862.],\n",
      "        [ 4910.],\n",
      "        [ 4000.],\n",
      "        [ 3496.],\n",
      "        [ 3649.],\n",
      "        [ 3086.],\n",
      "        [ 2715.],\n",
      "        [ 2344.],\n",
      "        [ 2005.],\n",
      "        [ 2086.],\n",
      "        [ 1397.],\n",
      "        [ 1596.],\n",
      "        [ 1722.],\n",
      "        [ 1863.],\n",
      "        [ 1739.],\n",
      "        [ 1835.],\n",
      "        [ 1854.],\n",
      "        [ 1646.],\n",
      "        [ 1564.],\n",
      "        [ 1720.],\n",
      "        [ 1355.],\n",
      "        [ 1602.],\n",
      "        [ 1808.],\n",
      "        [ 1763.],\n",
      "        [ 1839.],\n",
      "        [ 1859.],\n",
      "        [ 1764.],\n",
      "        [ 1569.],\n",
      "        [ 1200.]]) [25462. 31871. 32946. 30177. 20739. 15614. 14169. 12008.  7858.  4843.\n",
      "  4449.  3693.  2839.  1925.  1604.  1400.  1131.   611.   803.   853.\n",
      "   695.   746.   680.   710.   757.   854.   706.   733.   775.   864.\n",
      "   961.   957.   931.  1029.  1186.  1238.  1346.  1342.  1155.   978.\n",
      "  1180.  1730.  2108.  2492.  3193.  3821.  5453.  6328.  6244.  7515.\n",
      "  9927. 13332. 18742. 23043. 30094. 33053. 32960. 29401. 24535. 22700.\n",
      " 16544. 12018.  8687.  6716.  5378.  4436.  3626.  2789.  2534.  2240.\n",
      "  1928.  1708.  1664.  1649.  1567.  1583.  1666.  1707.  1691.  1764.\n",
      "  1911.  2010.  1867.  1918.  2028.  1974.  2013.  2022.  2198.  2381.\n",
      "  2326.  2588.  4260.  7393. 10219. 17192. 23783. 31143. 34414. 42059.\n",
      " 53583. 68115. 77947. 82639. 73235. 62633. 70597. 63046. 57944. 51051.\n",
      " 38756. 26830. 19285. 13464.  9618.  7523.  5753.  3667.  2788.  2009.\n",
      "  2182.  2126.  1865.  1617.  1752.  1489.  1315.  1389.  1232.  1796.\n",
      "  1983.  2055.  2137.  2373.  2436.  2250.  2743.  3414.  3687.  4406.\n",
      "  5342.  6495.  6700.  6490.  9577. 13976. 16027. 18224. 20563. 22151.\n",
      " 26691. 29194. 30018. 31082. 30073. 29853. 27062. 26327. 22610. 18943.\n",
      " 15590. 12421.  8880.  6115.  4266.  2789.  2321.  1385.  1317.  1048.\n",
      "  1083.   964.   895.   710.   805.   834.   826.   866.   889.   830.\n",
      "   991.  1145.  1004.  1125.  1132.  1445.  1829.  1714.  1873.  2009.\n",
      "  2046.  2166.  2242.  2150.  1951.  1880.  2097.  2332.  2258.  2236.\n",
      "  2551.  2828.  2923.  2937.  2449.  2576.  2699.  2607.  2480.  2203.\n",
      "  2241.  1994.  1856.  1366.  1408.  1358.  1169.  1293.  1156.   953.\n",
      "   782.   826.   672.   569.   589.   532.   576.   619.   665.   603.\n",
      "   805.   985.  1065.  1406.  1610.  1616.  1833.  1831.  1915.  1648.\n",
      "  1647.  1743.  1547.  1563.  1749.  1697.  1674.  1331.  1298.  1744.\n",
      "  2151.  2675.  2425.  2551.  2095.  2105.  2181.  2174.  2136.  2154.\n",
      "  2024.  1861.  2104.  2066.  1883.  1627.  1986.  1815.  1529.  1210.\n",
      "  1028.  1037.  1150.  1047.   970.   791.   602.   730.   664.   632.\n",
      "   569.   692.   688.   692.   588.   710.   748.   872.   906.   913.\n",
      "  1123.  1069.  1168.  1255.  1381.  1564.  1807.  2020.  2409.  2371.\n",
      "  2771.  4378.  5469.  7533. 10359. 13144. 16484. 18542. 20591. 19279.\n",
      " 21460. 25437. 28909. 32906. 36458. 39912. 41195. 44089. 43614. 46440.\n",
      " 43617. 34513. 25710. 19172. 16199. 12629. 10774.  6636.  4759.  3677.\n",
      "  3439.  2770.  2642.  2296.  2052.  2036.  1962.  2458.  2451.  1982.\n",
      "  2382.  2421.  2532.  2381.  2694.  2710.  2584.  3060.  3097.  3494.\n",
      "  3836.  3765.  4209.  6845.  9901. 13398. 17075. 19266. 24395. 27237.\n",
      " 23271. 23137. 24626. 22270. 15071. 13486. 12498. 11618. 11732. 10898.\n",
      " 10232.  9099.  7939.  5825.  4528.  4705.  4862.  4910.  4000.  3496.\n",
      "  3649.  3086.  2715.  2344.  2005.  2086.  1397.  1596.  1722.  1863.\n",
      "  1739.  1835.  1854.  1646.  1564.  1720.  1355.  1602.  1808.  1763.\n",
      "  1839.  1859.  1764.  1569.  1200.   508.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from forecastpnn.utils.plotting import plot_entire_confints\n",
    "\n",
    "set_seeds(RANDOM_SEED) # biggest outbreak 600, 900\n",
    "plot_entire_confints(dl, nowcast_pnn, weeks = WEEKS, random_split = RANDOM_SPLIT, test_idcs=test_idcs, total = False, xlims=[0, 418])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m set_seeds(RANDOM_SEED)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Write function to generate interval dict, and safe it if desired, then pass to standard evaluate_PI\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m levels_pnn \u001b[38;5;241m=\u001b[39m \u001b[43mpnn_PIs_indiv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnowcast_pnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRANDOM_SPLIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# can save if good scores and architecture to use for comparisons with others\u001b[39;00m\n\u001b[1;32m      5\u001b[0m _ \u001b[38;5;241m=\u001b[39m evaluate_PIs(levels_pnn, test_loader, return_coverages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_is_decomposed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/src/forecastpnn/utils/metrics.py:273\u001b[0m, in \u001b[0;36mpnn_PIs_indiv\u001b[0;34m(model, test_loader, n_samples, levels, future_obs, save, random_split)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m#preds[:, i] = np.squeeze(model(mat).sample().numpy())\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     temp_counts \u001b[38;5;241m=\u001b[39m model(mat)\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 273\u001b[0m     preds[:, i] \u001b[38;5;241m=\u001b[39m \u001b[43mform_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m min_preds, max_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mmax(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    275\u001b[0m pred_median \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mquantile(preds, \u001b[38;5;241m0.5\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/ForecastPNN/src/forecastpnn/utils/metrics.py:256\u001b[0m, in \u001b[0;36mform_predictions\u001b[0;34m(temp_counts, y, future_obs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Set to y where available, else is temp_counts, then sum\u001b[39;00m\n\u001b[1;32m    255\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((temp_counts\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m--> 256\u001b[0m result[:, :(future_obs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_obs\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    257\u001b[0m result[:, (future_obs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):] \u001b[38;5;241m=\u001b[39m temp_counts[:, (future_obs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):]\n\u001b[1;32m    258\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from forecastpnn.utils.metrics import pnn_PIs_indiv, evaluate_PIs\n",
    "set_seeds(RANDOM_SEED)\n",
    "## Write function to generate interval dict, and safe it if desired, then pass to standard evaluate_PI\n",
    "levels_pnn = pnn_PIs_indiv(nowcast_pnn, test_loader, random_split = RANDOM_SPLIT, save=False, future_obs=0) # can save if good scores and architecture to use for comparisons with others\n",
    "_ = evaluate_PIs(levels_pnn, test_loader, return_coverages=False, return_is_decomposed=False, total = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".fpnn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
